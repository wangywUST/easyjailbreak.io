<!DOCTYPE html>
<html>

<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-DERZX1PWZ4"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-DERZX1PWZ4');
  </script>

  <meta charset="utf-8">
  <meta name="description" content="Frustratingly Easy Jailbreak of Large Language Models via Output Prefix Attacks">
  <meta name="keywords"
    content="Jailbreak, Output Prefix Attacks, Large Language Models, GPT">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Frustratingly Easy Jailbreak of Large Language Models via Output Prefix Attacks</title>

  <!-- Google Tag Manager -->
  <script>(function (w, d, s, l, i) {
      w[l] = w[l] || []; w[l].push({
        'gtm.start':
          new Date().getTime(), event: 'gtm.js'
      }); var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
          'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-MFCT45H');</script>
  <!-- End Google Tag Manager -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/tifa.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MFCT45H" height="0" width="0"
      style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->


  <!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://yushi-hu.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://finegrainedrlhf.github.io/">
            Fine-Grained RLHF
          </a>
          <a class="navbar-item" href="https://yushi-hu.github.io/promptcap_demo/">
            PromptCap
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              â™Ÿ
              Frustratingly Easy Jailbreak of Large Language Models via Output Prefix Attacks
            </h1>
            <div class="is-size-5">
              <span class="author-block">
                <a href="https://wangywust.github.io/" style="color:#008AD7;font-weight:normal;">Yiwei Wang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://muhaochen.github.io/" style="color:#f68946;font-weight:normal;">Muhao Chen</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://vnpeng.net/" style="color:#008AD7;font-weight:normal;">Nanyun Peng</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://web.cs.ucla.edu/~kwchang/" style="color:#008AD7;font-weight:normal;">Kai-Wei Chang</a><sup>1</sup>,
              </span>
            </div>
  
            <br>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><b style="color:#008AD7; font-weight:normal">â–¶ </b>University of California, Los Angeles</span>
              <span class="author-block"><b style="color:#f68946; font-weight:normal">â–¶ </b>University of California, Davis</span>
            </div>

            
              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- PDF Link. -->
                  <span class="link-block">
                    <a href="https://www.researchsquare.com/article/rs-4385503/latest" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

              <!-- code Link. -->
              <span class="link-block">
                <a href="https://github.com/wangywUST/DeepEdit" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
    
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle">
          <div class="content has-text-justified">
  We propose <b>Opra</b> and <b>OpraTea</b> ðŸ†˜, two novel, effective, and extremely simple jailbreak methods that can attack all large language models (LLMs) without expensive optimization or parameter search. 
<br><br><br>
      <!-- <center><img src="./static/images/frame.gif" alt="teaser"></center> -->
      <center><img src="./static/images/fig_1.jpg" alt="teaser" width="75%"></center>
      
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Recent research has devoted significant effort to identifying security vulnerabilities in large language models (LLMs). These vulnerabilities may enable malicious entities to manipulate LLMs to produce harmful outputs, a.k.a., jailbreaks.<br><br>
          
          Most previous work on jailbreak attacks focuses on designing adversarial input prompts based on costly optimization methods. Different from them, we identify significant security risks associated with attacks on the output side. In particular, we propose two output prefix jailbreak attacks that can effectively disrupt model alignment: Opra and OpraTea.<br><br>
          
          Opra enforces the output prefix of LLMs to follow a "fuse", a probed template that expresses positive attitudes towards addressing the input question, even when the user has malicious intent. OpraTea hides the malicious target within the input prompt to bypass the "content filter" designed to detect and block malicious inputs. Both methods are simple yet threaten the security of LLMs because (1) they do not require any expensive optimization or parameter search; (2) the setting up and execution of our methods only requires a single LLM inference; and (3) they can operate on any black-box LLMs.<br><br>

          Empirically, Opra and OpraTea increase the misalignment rate in popular LLMs, achieving a higher successful rate than the baseline with 1000x lower computational cost.<br>  <br>            
              <center><img src="./static/images/fig_2.png" alt="teaser" width="100%"></center>
          </p>

        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">A New Family of LLMs' Jailbreak Attacks</h2>
        <div class="content has-text-justified">
          <p>
          In this paper, we investigate a new family of jailbreak methods, Output Prefix Attacks, that manipulates the prefix of LLMs' output. 
          Our output attacks are simpler, more efficient, and more effective than prior jailbreak approaches, posing a substantial security risk to LLMs.
          Our research is inspired by the observation that LLMs tend to generate informative responses when the output prefix conveys a willingness to follow the user's instructions or answer the user's questions.
        </p>

        <center><img src="./static/images/fig_3.jpg" alt="teaser" width="80%"></center>
          

        <a href="https://www.researchsquare.com/article/rs-4385503/latest" target="_blank">See more details in our paper</a>
        </div>
      </div>
    </div>
    <!--/ Abstract -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Designing Decoding Constraints for Knowledge Editing</h2>
        <div class="content has-text-justified">
          <p>
            <strong>The central idea is to view knowledge editing as a problem of decoding with constraints.</strong><br>
            We propose to impose semantic constraints on the LLMs' outputs to represent the desired properties that benefit knowledge editing.
            Specifically, we propose the following constraints: <strong>Conciseness</strong> <span>&#128205;</span> prevents the redundant loops of reasoning; <strong>Coherence</strong> <span>&#128062;</span>  guarantees the coherence of adjacent steps; <strong>Receptiveness</strong> <span>&#128161;</span> guarantees the LLMs' awareness of new knowledge; <strong>Pertinence</strong> <span>&#128588;</span> improves the relevance of reasoning to the input question.
            These constraints improve LLMsâ€™ reasoning with new knowledge from different perspectives as a whole.
        </p>

        <center><img src="./static/images/fig_10.png" alt="teaser" width="100%"></center>
          

<a href="https://arxiv.org/abs/2401.10471" target="_blank">See more details in our paper</a>
        </div>
      </div>
    </div>
    <!--/ Abstract -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" id="privacy-auditing">Decoding at The Reasoning Step Level</h2>
        <div class="content has-text-justified">
          <p>
            In this work, we change the granularity of decoding from the token level to the reasoning step level. Our decoding is designed at the step level: instead of taking the tokens predefined in a fixed vocabulary as the candidates, we take the reasoning steps as the candidates. At every iteration, we let LLMs to produce one reasoning step and retrieve a fixed number of new facts in parallel to the reasoning step as the step candidates. The new fact retrieval is based on the nearest neighbor search with the sentence-level embeddings given by BERT. The motivation of this design is that the new facts that are semantically close to the generated facts are more likely to satisfy the constraints. 
          </p>

          <p>
            Taking the single generated step and the new facts as the step candidates, we filter a valid candidate and take it as the new reasoning step. Note that there may exist more than one candidates that satisfy the constraints. We will introduce how we design the decoding constraints for KE in Section 3.2, how we verify the constraints in Section 3.3 and Section 3.4, and how we process the multiple valid step candidates to search for the optimal path of LLMs' multi-hop reasoning in Section 3.5. 
          </p>

          <p>
            <b>Our decoding design bypasses the requirement of accessing the token-wise distributions, since all the decoding actions are defined over the step level. Our decoding strategy is free to be applied to black-box LLMs in order to produce satisfactory outputs in accordance with new knowledge.</b>
          </p>
          <p>
            <img src="./static/images/fig_18.png"
              alt="Graph depicting the process of unlearning Harry Potter content">
          </p>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" id="privacy-auditing">Local Constraint Verifier</h2>
        <div class="content has-text-justified">
          <p>
            We store the candidates that satisfy the local verifier âš– in a stack for further use. 
            Instead of simply retaining only one candidate, we store all the candidates in the stack ðŸ“š, since we have the global verifier that has to verify the reasoning steps from the whole reasoning process.
            The correctness of a reasoning step has to be finally decided by the global verifier. 
          </p>
          <p>
            <img src="./static/images/fig_15.png"
              alt="Graph depicting the process of unlearning Harry Potter content">
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" id="privacy-auditing">Global Constraint Verifier</h2>
        <div class="content has-text-justified">
          <p>
            The global verifier âš– determines the feasibility of the whole reasoning process by checking whether the answer is found.
            If not feasible, we pop the status stack ðŸ“š to use another reasoning subprocess that satisfies the local verifier. 
          </p>
          <p>
            <img src="./static/images/fig_16.png"
              alt="Graph depicting the process of unlearning Harry Potter content">
          </p>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- <h2 class="title is-3" id="copyrighted-detection">Copyrighted Book Detection</h2> -->
        <h2 class="title is-3" id="copyrighted-detection">Performance of Knowledge Editing</h2>
        <div class="content has-text-justified">

        <!-- <title>Top 20 Copyrighted Books in GPT-3's (text-davinci-003) Pretraining Data detected by Min-K% Prob</title> -->
        <style>
          table {
            width: 100%;
            border-collapse: collapse;
          }

          table,
          th,
          td {
            border: 1px solid black;
          }

          th,
          td {
            padding: 8px;
            text-align: left;
          }

          th {
            background-color: #f2f2f2;
          }
        </style>
      </head>

      <body>

        <table>
          <caption><b style="color: red;">Experimental results (accuracy; %) on the dataset MQuAKE-3k with the KE batch size of 100. </caption>
          <thead>
            <tr>
              <th>Method</th>
              <th>MQuAKE-3k</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>text-davinci-003 w/ MeLLo </td>
              <td>32.2</td>
            </tr>
            <tr>
              <td>text-davinci-003 w/ <strong>DEEPEDIT (Ours)</strong></td>
              <td><strong>49.1</strong></td>
            </tr>
            <tr>
              <td>gpt-3.5-turbo-instruct w/ MeLLo </td>
              <td>29.9</td>
            </tr>
            <tr>
              <td>gpt-3.5-turbo-instruct w/ <strong>DEEPEDIT (Ours)</strong></td>
              <td><strong>47.2</strong></td>
            </tr>
          </tbody>
        </table>

      </body>


          <p>
            <img src="./static/images/fig_19.png"
              alt="Graph depicting the process of unlearning Harry Potter content">
          </p>

          <p>
            <img src="./static/images/fig_20.png"
              alt="Graph depicting the process of unlearning Harry Potter content">
          </p>

      </html>

    </div>
  </div>
</section>


      <section class="section is-light" id="BibTeX">
        <div class="container is-max-desktop content">
          <h2 class="title">BibTeX</h2>
          <pre><code>
@misc{wang2024deepedit,
title={DeepEdit: Knowledge Editing as Decoding with Constraints},
author={Yiwei Wang and Muhao Chen and Nanyun Peng and Kai-Wei Chang},
year={2024},
eprint={2401.10471},
archivePrefix={arXiv},
primaryClass={cs.CL}
}
</code></pre>
        </div>
      </section>



      <footer class="footer">
        <div class="container">
          <div class="columns is-centered">
            <div class="column is-8">
              <div class="content">
                <p>
                  This website is licensed under a <a rel="license"
                    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                    Commons Attribution-ShareAlike 4.0 International License</a>.
                </p>
                <p>
                  This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source
                    code</a> of this website,
                  we just ask that you link back to this page in the footer.
                  Please remember to remove the analytics code included in the header of the website which
                  you do not want on your website.
                </p>
              </div>
            </div>
          </div>
        </div>
      </footer>

</body>

</html>
