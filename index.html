<!DOCTYPE html>
<html>

<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-DERZX1PWZ4"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-DERZX1PWZ4');
  </script>

  <meta charset="utf-8">
  <meta name="description" content="Frustratingly Easy Jailbreak of Large Language Models via Output Prefix Attacks">
  <meta name="keywords"
    content="Jailbreak, Output Prefix Attacks, Large Language Models, GPT">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Frustratingly Easy Jailbreak of Large Language Models via Output Prefix Attacks</title>

  <!-- Google Tag Manager -->
  <script>(function (w, d, s, l, i) {
      w[l] = w[l] || []; w[l].push({
        'gtm.start':
          new Date().getTime(), event: 'gtm.js'
      }); var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
          'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-MFCT45H');</script>
  <!-- End Google Tag Manager -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/tifa.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MFCT45H" height="0" width="0"
      style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->


  <!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://yushi-hu.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://finegrainedrlhf.github.io/">
            Fine-Grained RLHF
          </a>
          <a class="navbar-item" href="https://yushi-hu.github.io/promptcap_demo/">
            PromptCap
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              â™Ÿ
              Frustratingly Easy Jailbreak of Large Language Models via Output Prefix Attacks
            </h1>
            <div class="is-size-5">
              <span class="author-block">
                <a href="https://wangywust.github.io/" style="color:#008AD7;font-weight:normal;">Yiwei Wang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://muhaochen.github.io/" style="color:#f68946;font-weight:normal;">Muhao Chen</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://vnpeng.net/" style="color:#008AD7;font-weight:normal;">Nanyun Peng</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://web.cs.ucla.edu/~kwchang/" style="color:#008AD7;font-weight:normal;">Kai-Wei Chang</a><sup>1</sup>,
              </span>
            </div>
  
            <br>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><b style="color:#008AD7; font-weight:normal">â–¶ </b>University of California, Los Angeles</span>
              <span class="author-block"><b style="color:#f68946; font-weight:normal">â–¶ </b>University of California, Davis</span>
            </div>

            
              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- PDF Link. -->
                  <span class="link-block">
                    <a href="https://www.researchsquare.com/article/rs-4385503/latest" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

              <!-- code Link. -->
              <span class="link-block">
                <a href="https://github.com/wangywUST/DeepEdit" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
    
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle">
          <div class="content has-text-justified">
  We propose <b>Opra</b> and <b>OpraTea</b> ðŸ†˜, two novel, effective, and extremely simple jailbreak methods that can attack all large language models (LLMs) without expensive optimization or parameter search. 
<br><br><br>
      <!-- <center><img src="./static/images/frame.gif" alt="teaser"></center> -->
      <center><img src="./static/images/fig_1.jpg" alt="teaser" width="75%"></center>
      
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Recent research has devoted significant effort to identifying security vulnerabilities in large language models (LLMs). These vulnerabilities may enable malicious entities to manipulate LLMs to produce harmful outputs, a.k.a., jailbreaks.<br><br>
          
          Most previous work on jailbreak attacks focuses on designing adversarial input prompts based on costly optimization methods. Different from them, we identify significant security risks associated with attacks on the output side. In particular, we propose two output prefix jailbreak attacks that can effectively disrupt model alignment: Opra and OpraTea.<br><br>
          
          Opra enforces the output prefix of LLMs to follow a "fuse", a probed template that expresses positive attitudes towards addressing the input question, even when the user has malicious intent. OpraTea hides the malicious target within the input prompt to bypass the "content filter" designed to detect and block malicious inputs. Both methods are simple yet threaten the security of LLMs because (1) they do not require any expensive optimization or parameter search; (2) the setting up and execution of our methods only requires a single LLM inference; and (3) they can operate on any black-box LLMs.<br><br>

          Empirically, Opra and OpraTea increase the misalignment rate in popular LLMs, achieving a higher successful rate than the baseline with 1000x lower computational cost.<br>  <br>            
              <center><img src="./static/images/fig_2.png" alt="teaser" width="100%"></center>
          </p>

        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">A New Family of LLMs' Jailbreak Attacks</h2>
        <div class="content has-text-justified">
          <p>
          In this paper, we investigate a new family of jailbreak methods, Output Prefix Attacks, that manipulates the prefix of LLMs' output. 
          Our output attacks are simpler, more efficient, and more effective than prior jailbreak approaches, posing a substantial security risk to LLMs.
          Our research is inspired by the observation that LLMs tend to generate informative responses when the output prefix conveys a willingness to follow the user's instructions or answer the user's questions.
        </p>

        <center><img src="./static/images/fig_3.jpg" alt="teaser" width="80%"></center>
          

        <a href="https://www.researchsquare.com/article/rs-4385503/latest" target="_blank">See more details in our paper</a>
        </div>
      </div>
    </div>
    <!--/ Abstract -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Simple, Efficient and Effective Attack</h2>
        <div class="content has-text-justified">
          <p>
            To systematically evaluate our approach, we apply jailbreaks on LLMs spanning both the open-source and closed-source LLMs.
            We conduct the empirical evaluation on two popular jailbreak benchmarks, MaliciousInstruct and AdvBench, which cover a broad spectrum of malicious intents to enhance the diversity of scenarios.
            Empirical results show that our Opra and OpraTea achieve higher attack successful rates than the strong jailbreak baselines with 1,000x lower computational costs.
            The human evaluation further suggests that of the unauthorized responses, at least 80% actually contain harmful instructions.
        </p>

        <center><img src="./static/images/fig_4.png" alt="teaser" width="100%"></center>
          

<a href="https://arxiv.org/abs/2401.10471" target="_blank">See more details in our paper</a>
        </div>
      </div>
    </div>
    <!--/ Abstract -->
  </div>
</section>


      <section class="section is-light" id="BibTeX">
        <div class="container is-max-desktop content">
          <h2 class="title">BibTeX</h2>
          <pre><code>
@article{wang2024frustratingly,
  title={Frustratingly Easy Jailbreak of Large Language Models via Output Prefix Attacks},
  author={Wang, Yiwei and Chen, Muhao and Peng, Nanyun and Chang, Kai-Wei},
  year={2024}
}
</code></pre>
        </div>
      </section>



      <footer class="footer">
        <div class="container">
          <div class="columns is-centered">
            <div class="column is-8">
              <div class="content">
                <p>
                  This website is licensed under a <a rel="license"
                    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                    Commons Attribution-ShareAlike 4.0 International License</a>.
                </p>
                <p>
                  This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source
                    code</a> of this website,
                  we just ask that you link back to this page in the footer.
                  Please remember to remove the analytics code included in the header of the website which
                  you do not want on your website.
                </p>
              </div>
            </div>
          </div>
        </div>
      </footer>

</body>

</html>
